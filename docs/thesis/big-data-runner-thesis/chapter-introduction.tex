\chapter{Wstęp} \label{chap.introduction}
{placeholder}

\section{Problematyka operacji w kontekscie platform równoległych. Batch, streaming, operacje leniwe.}
W dzisiejszym świecie występują ogromne ilości danych, które są produkowane przez człowieka. Daje to ogromne możliwości do wszelkiego rodzaju wnioskowań, aczkolwiek jednocześnie wymaga ogromnego nakładu pracy. W związku w upowszechnieniem się automatyzacji zaczęto pracować nad koncepcją przetwarzania danych w sposób równoległy tak aby proces przebiegał jak najszybciej i efektywniej. Takie podejście do przetwarzania danych zrodziło problemy, które musiały zostać rozwiązane aby zyski ze skomplikowania architektury obliczeń przewyszyły koszty. Jednym z największych wyzwań podczas zrównoleglenia obliczeń jest synchronizacja danych zależnych jak również ich poprawność w danej jednostce czasu w danej części systemu obliczeń. Jednoczenśnie dzięki takiemu podejściu zaoszczędzono nakład pracy poświęcony na konstruowanie komputera o dużej mocy obliczeniowej, który byłby w stanie wykonywać zadania sekwencyjnie zachowując takie same wyniki jeżeli chodzi o szybkość obliczeń. Komputery o dedykowanej architekturze procesora zastąpiono sprzętem dedykowanym dla przeciętego użytkownika, które w połączeniu dwóch lub więcej utworzyły klaster. Taka architektura pozwala na oszczedności w krótko oraz długo terminowym okresie czasu. Cena zakupu wielu komputerów, jest zazwyczaj niższa niż jeden komputer o dużej mocy obliczeniowej, utrzymanie jest również tańsze gdyż nie jest wymagana kadra o wąskiej specjalizacji. Dodatkowym aspektem może być również system chłodzenia - dedykowany dla komputera o dużej mocy. Standardowy komputer posiada wbudowany system chłodzenia, który nie wymaga uwzględnienia w kosztorysie. W kontekscie przetwarzania równoległego przy rozważaniu danych masowych możemy rozróżnić dwa rozdzaje przetwarzania: \textbf{batch} oraz \textbf{streaming}.
\subsection{Batch}\label{batch_subsection} 
Batch jest pojęciem zdefiniowanym w tym samym czasie gdy pojawiły się same komputery. Jest to wykonywanie poszczególnych operacji bez nadzoru człowieka (interaktywności). W kontekście danych masowych możemy przyjąć, że są to operacje analizy danych, które nie są wykonywane w czasie rzeczywistym np. generacja raportu na podstawie danych, które zostały zebrane od wielu klientów sklepu. Człowiek definiuje zadanie, programuje proces obliczeń, podaje dane wejściowe i oczekuje na wyniki dostarczone przez system informatyczny. Takie działanie charakteryzuje się odczuwalnym czasem oczekiwania (nie mylić z latencją). Jednocześnie użytkownik nie koniecznie potrzebuje wyników obliczeń natychmiastowo. Takie podejście może satyfkacjonować końcowego użytkownika, jeżeli chodzi o koszty obliczeń w zestawieniu do czasu otrzymania rezultatów.
\subsection{Streaming}\label{streaming_subsection}
Streaming (przetwarzanie strumieniowe) - jest pojęciem antagonistycznym do przetwarzania typu batch, jednocześnie w swojej implementacji wykorzystuje jego założenia. Streaming to przetwarzanie danych w czasie rzeczywistym - dostarczenie wyników dla użytkownika bez zauważalnego czasu czasu oczekiwania. Takie podejście jest często wykorzywane podczas notowań giełdowych gdzie wartości indeksów spółek zmieniają się bardzo szybko w krótkiej ilości czasu. Jednocześnie użytkownik oczekuje rezultatów obliczeń jak najszybciej, by decyja jakie akcje sprzedać/kupić mogła zostać podjęta. Streaming to przetwarzanie danych, które napływają w sposób ciągły, są dystrubowane na mniejsze części (batch) i delegowane do obliczeń. Po uzyskaniu rezultat jest zwracany do użytkownika. W takim podejściu użytkownik jest nakierowany na krótki czas oczekiwania i błyskawiczną informację zwrotną. Moc obliczeniową sprzętu dedykuje się pod dane wejściowe tak by osiągnąć jak najkrótszy czas odpowiedzi a latencję (czas obsługi rządania obliczeń po stronie serwera wykonującego obliczenia) stara się minimalizować do poziomu zera.
\subsection{Operacje leniwe}
Operacje leniwe to technika stosowana by zoptymalizować obliczenia. Polega na opóźnianiu obliczeń do momentu aż rezultat nie jest faktycznie wymagany. Można przyjąć, że "potokuje" poszczególne operacje jednoczesnie unikając zbędnej wymiany danych. Prostym przykładem może być zapisanie odczyt dużego pliku danych, zliczeniu wystąpień zadanej frazy i zapisanie wyniku w postaci innego pliku. Jeżeli taką akcję zdefinujemy jako leniwą całe obliczenie zostanie wywołane w momencie zapisania do pliku wynikowego. Jeżeli zapisanie do pliku wynikowego nie zostanie uruchomione operacje odczytu pliku, filtrowania po zadanej frazie również. Dzięki temu obciążenie systemu obliczeń nie jest generowane do momentu, aż jest to faktycznie potrzebne. 

\section{Cele pracy}
Głównym celem pracy jest dogłębna analiza dwóch narzędzi do przetwarzania danych masowych w architekturze równoległej: Apache Spark\footnote{\url{http://spark.apache.org/}} oraz Apache Hadoop.\footnote{\url{https://hadoop.apache.org/}} Spark to projekt dosyć nowy projekt o otwartym kodzie źródłowym. Pierwsze wydanie nastąpiło 30 maja 2014. Wersja poddana badaniom to 2.1.0 wydana 28 grudnia 2016. Hadoop to narzędzie już dobrze znane na rynku ETL (pierwsze wydanie 27 grudnia 2001), wersja poddana analizie to 2.7.3 wydana 25 sierpnia 2016. Hadoop to rozwiązanie również na licencji otwartego kodu źródłowego. Analiza dotyczy takich czynników jak:
\begin{itemize}
	\item Wymagania sprzętowe, które stawiają oba narzędzia, które muszą być spełnione aby dostarczyć rezultaty obliczeń
	\item Wyniki czasowe przetwarzania zadanej próbki wejściowej
	\item Złożoność obsługi obu platform
	\item Koszty rekrutacji oraz szkolenia kadry wyspecjalizowanej w danej platformie
\end{itemize}
Do analizy powstało narzędzie oparte na szkielecie aplikacji internetowych Play\footnote{\url{https://playframework.com/}}, które udostępnia interfejs HTTP dla operacji przetwarzania danych dla obydwu platform. Narzędzie to posłużyło do dostarczenia rezultatów, które mogły zostać poddane analizie ze względu na kryteria podane powyżej. Poza badaniami wykonanymi w pracy dokonana została ocena możliwości komercyjnego rozwoju portotypowego narzędzia powstałego na potrzeby analizy. Dodatkowo oceniona została opłacalność migracji z narzędzia Apache Hadoop na Apache Spark ze względu na wymagania końcowego użytkownika. 

\section{Przegląd literatury}
\todo{Czy ten rozdział jest potrzebny?}
\section{Przegląd rozdziałów}
\todo{krótkie opisy poszczególnych rodziałów}