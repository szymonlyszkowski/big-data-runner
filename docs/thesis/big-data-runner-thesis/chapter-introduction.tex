\chapter{Wstęp} \label{chap.introduction}
Tematyka niniejszej pracy magisterskiej dotyczy niedawno powstałej dziedziny informatyki jaką jest przetwarzanie danych masowych. Praca skupia się głównie na dwóch najpopularniejszych narzędziach używanych w procesie przetwarzania danych masowych dostępnych na licencji otwartego kodu źródłowego: Apache Spark i Apache Hadoop. Najważniejszym elementem pracy jest kompleksowe porównanie obu platform tak by dać użytkownikowi możliwość oceny, które narzędzie jest szybsze, tańsze w rozwijaniu i utrzymaniu oraz czy warto migrować z jednej platformy na drugą i odwrotnie. Podczas przeprowadzonych badań powstała aplikacja internetowa, która posłużyła jako narzędzie dostarczające wyniki wydajności dla analizy porównawczej, jak również łatwości pod względem dalszego rozwoju. Źródłem danych masowych jest \textit{Twitter Developer API}, które udostępnia publiczne dane serwisu \textit{Twitter}, aktualizowane w czasie rzeczywistym. Aplikacja została oparta na dwóch językach programowania Scala oraz Java, jednocześnie wykorzystuje ramę projektową \textit{Play!} oraz narzędzie do budowania i zarządzania cyklem dostarczania oprogramowania \textit{Scala Build Tool}. Wersjonowanie kodu źródłowego zostało zrealizowane przy pomocy systemu kontroli wersji \textit{Git}. 

\section{Problematyka operacji w kontekście platform równoległych. Batch, streaming, operacje leniwe.}
W dzisiejszym świecie występują ogromne ilości danych, które są produkowane przez człowieka. Daje to ogromne możliwości do wszelkiego rodzaju wnioskowań, aczkolwiek jednocześnie wymaga ogromnego nakładu pracy. W związku w upowszechnieniem się automatyzacji zaczęto pracować nad koncepcją przetwarzania danych w sposób równoległy tak aby proces przebiegał jak najszybciej i efektywniej. Takie podejście do przetwarzania danych zrodziło problemy, które musiały zostać rozwiązane aby zyski ze skomplikowania architektury obliczeń przewyższyły koszty. Jednym z największych wyzwań podczas zrównoleglenia obliczeń jest synchronizacja danych zależnych jak również ich poprawność w danej jednostce czasu w danej części systemu obliczeń. Jednocześnie dzięki takiemu podejściu zaoszczędzono nakład pracy poświęcony na konstruowanie komputera o dużej mocy obliczeniowej, który byłby w stanie wykonywać zadania sekwencyjnie zachowując takie same wyniki jeżeli chodzi o szybkość obliczeń. Komputery o dedykowanej architekturze procesora zastąpiono sprzętem dedykowanym dla przeciętego użytkownika, które w połączeniu dwóch lub więcej utworzyły klaster. Taka architektura pozwala na oszczędności w krótko oraz długo terminowym okresie czasu. Cena zakupu wielu komputerów, jest zazwyczaj niższa niż jeden komputer o dużej mocy obliczeniowej, utrzymanie jest również tańsze gdyż nie jest wymagana kadra o wąskiej specjalizacji. Dodatkowym aspektem może być również system chłodzenia - dedykowany dla komputera o dużej mocy. Standardowy komputer posiada wbudowany system chłodzenia, który nie wymaga uwzględnienia w kosztorysie. W kontekście przetwarzania równoległego przy rozważaniu danych masowych możemy rozróżnić dwa rodzaje przetwarzania: \textbf{batch} oraz \textbf{streaming}.
\subsection{Batch}\label{batch_subsection} 
Batch jest pojęciem zdefiniowanym w tym samym czasie gdy pojawiły się same komputery. Jest to wykonywanie poszczególnych operacji bez nadzoru człowieka (interaktywności). W kontekście danych masowych możemy przyjąć, że są to operacje analizy danych, które nie są wykonywane w czasie rzeczywistym np. generacja raportu na podstawie danych, które zostały zebrane od wielu klientów sklepu. Człowiek definiuje zadanie, programuje proces obliczeń, podaje dane wejściowe i oczekuje na wyniki dostarczone przez system informatyczny. Takie działanie charakteryzuje się odczuwalnym czasem oczekiwania (nie mylić z latencją). Jednocześnie użytkownik nie koniecznie potrzebuje wyników obliczeń natychmiastowo. Takie podejście może satysfakcjonować końcowego użytkownika, jeżeli chodzi o koszty obliczeń w zestawieniu do czasu otrzymania rezultatów.
\subsection{Streaming}\label{streaming_subsection}
Streaming (przetwarzanie strumieniowe) - jest pojęciem antagonistycznym do przetwarzania typu batch, jednocześnie w swojej implementacji wykorzystuje jego założenia. Streaming to przetwarzanie danych w czasie rzeczywistym - dostarczenie wyników dla użytkownika bez zauważalnego czasu czasu oczekiwania. Takie podejście jest często wykorzystywane podczas notowań giełdowych gdzie wartości indeksów spółek zmieniają się bardzo szybko w krótkiej ilości czasu. Jednocześnie użytkownik oczekuje rezultatów obliczeń jak najszybciej, by decyzja jakie akcje sprzedać/kupić mogła zostać podjęta. Streaming to przetwarzanie danych, które napływają w sposób ciągły, są dystrybuowane na mniejsze części (batch) i delegowane do obliczeń. Po uzyskaniu rezultat jest zwracany do użytkownika. W takim podejściu użytkownik jest nakierowany na krótki czas oczekiwania i błyskawiczną informację zwrotną. Moc obliczeniową sprzętu dedykuje się pod dane wejściowe tak by osiągnąć jak najkrótszy czas odpowiedzi a latencję (czas obsługi żądania obliczeń po stronie serwera wykonującego obliczenia) stara się minimalizować do poziomu zera.
\subsection{Operacje leniwe}
Operacje leniwe to technika stosowana by zoptymalizować obliczenia. Polega na opóźnianiu obliczeń do momentu aż rezultat nie jest faktycznie wymagany. Można przyjąć, że "potokuje" poszczególne operacje jednocześnie unikając zbędnej wymiany danych. Prostym przykładem może być zapisanie odczyt dużego pliku danych, zliczeniu wystąpień zadanej frazy i zapisanie wyniku w postaci innego pliku. Jeżeli taką akcję zdefiniujemy jako leniwą całe obliczenie zostanie wywołane w momencie zapisania do pliku wynikowego. Jeżeli zapisanie do pliku wynikowego nie zostanie uruchomione operacje odczytu pliku, filtrowania po zadanej frazie również. Dzięki temu obciążenie systemu obliczeń nie jest generowane do momentu, aż jest to faktycznie potrzebne. 

\section{Cel pracy}
Celem pracy jest wykazanie przewagi zastosowania spośród dwóch narzędzi do przetwarzania danych masowych w architekturze równoległej: Apache Spark\footnote{\url{http://spark.apache.org/}} oraz Apache Hadoop.\footnote{\url{https://hadoop.apache.org/}} Spark to projekt dosyć nowy projekt o otwartym kodzie źródłowym. Pierwsze wydanie nastąpiło 30 maja 2014. Wersja poddana badaniom to 2.1.0 wydana 28 grudnia 2016. Hadoop to narzędzie już dobrze znane na rynku ETL\footnote{Extract,Transform,Load} (pierwsze wydanie 27 grudnia 2001), wersja poddana analizie to 2.7.3 wydana 25 sierpnia 2016. Hadoop to rozwiązanie również na licencji otwartego kodu źródłowego. Czynniki uwzględniane, które stanowią przewagę w kontekście porównania dwóch narzędzi to:
\begin{itemize}
	\item Wymagania sprzętowe, które stawiają oba narzędzia, które muszą być spełnione aby dostarczyć rezultaty obliczeń
	\item Wyniki czasowe przetwarzania zadanej próbki wejściowej
	\item Złożoność obsługi obydwu platform
	\item Koszty rekrutacji oraz szkolenia kadry wyspecjalizowanej w danej platformie
\end{itemize}
Podczas wykonywania badań w kontekście obydwu platform powstało narzędzie oparte na szkielecie aplikacji internetowych Play!\footnote{\url{https://playframework.com/}}, które udostępnia protokół HTTP dla operacji przetwarzania danych dla obydwu platform. Narzędzie to posłużyło do dostarczenia rezultatów, które mogły zostać poddane analizie ze względu na kryteria podane powyżej. Poza badaniami wykonanymi w pracy dokonana została ocena możliwości komercyjnego rozwoju prototypowego narzędzia powstałego na potrzeby analizy. Dodatkowo oceniona została opłacalność migracji z narzędzia Apache Hadoop na Apache Spark ze względu na wymagania końcowego użytkownika.
\section{Przegląd rodziałów}
Reszta tej pracy jest podzielona na cztery rozdziały: \ref{chap.big-data-processing} - \textit{Przetwarzanie danych masowych na platformach równoległych}, \ref{chap.technology-stack} - \textit{Metodologia badań}, \ref{chap.research} - \textit{Badania}, \ref{chap.summary} - \textit{Podsumowanie}. Rozdział \ref{chap.big-data-processing} przedstawia podstawowe pojęcia, które są używane w dziedzinie przetwarzania danych masowych. Dodatkowo porusza też ważne zagadnienie dotyczące rozproszonego systemu plików zdolnego przechowywać dane masowe, jak również reprezentacji danych masowych jako kolekcji danych. Część \ref{chap.technology-stack} opisuje architekturę aplikacji, która powstała na potrzeby tej pracy magisterskiej. Rozdział zawiera opis wszystkich funkcjonalności jakie aplikacja dostarcza użytkownikowi. Rozdział \textit{Badania} opisuje sposób przeprowadzania badań przy użyciu powstałej aplikacji, zawiera wyniki wydajności operacji, które dostarcza aplikacja oraz opis danych, które były użyte podczas testów wydajności. Kolejnym aspektem poruszonym podczas badań są koszty rozwoju i utrzymania systemu ze względu na zastosowaną platformę oraz język programowania. Ostatni rozdział podsumowuje wyniki wszystkich badań przeprowadzonych w tej pracy magisterskiej, zawiera dyskusje na temat przewagi zastosowania jednej z platform ze względu na okoliczności. Opisuje również możliwości komercyjnego rozwoju aplikacji \textit{big-data-runner}.